(dp1
S'output'
p2
S"<class 'gluon.contrib.pymysql.err.InternalError'> (1701, u'Cannot truncate a table referenced in a foreign key constraint (`pestlist`.`duo_archive`, CONSTRAINT `duo_archive_ibfk_1` FOREIGN KEY (`current_record`) REFERENCES `pestlist`.`duo` (`id`))')"
p3
sS'layer'
p4
S'/home/aubreymoore/Devel/playpen/web2py/applications/pestlist/controllers/default.py'
p5
sS'code'
p6
S'# -*- coding: utf-8 -*-\n\n\ndef display_taxonomic_tree():\n    import json\n    # Important: root nodes must have \'parent\':\'#\'\n    m = None\n    #root_taxon = \'\'\n\n    form=FORM(\'Root taxon (leave blank to include all taxa):\',\n        INPUT(_name=\'root_taxon\'),\n        INPUT(_type=\'submit\'),\n    )\n\n    if form.accepts(request,session):\n\n        root_taxon = form.vars.root_taxon\n        print(root_taxon)\n\n        #level_dict = {\'kingdom\':1,\'phylum\':2,\'class\':3,\'order\':4,\'family\':5,\'genus\':6,\'species\':7}\n        if root_taxon == \'\':\n            rows = db(db.taxon2).select(orderby=db.taxon2.lineage)\n        else:\n            rows = db(db.taxon2.lineage.contains(root_taxon)).select(orderby=db.taxon2.lineage)\n            rows[0].parent_tid = \'#\'\n\n        mylist = []\n        for row in rows:\n            if row.trank in [\'genus\',\'species\']:\n                text = \'{} <i>{}</i>\'.format(row.trank, row.name)\n            else:\n                text = \'{} {}\'.format(row.trank, row.name)\n            mylist.append({\'id\':row.tid,\'parent\':row.parent_tid,\'text\':text})\n        m = json.dumps(mylist)\n\n    elif form.errors:\n        response.flash = \'form has errors\'\n    else:\n        response.flash = \'Please select a root taxon and press "SUBMIT QUERY".\'\n    return dict(form=form, m=m)\n\n\ndef populate_resolved_names_table():\n    db.resolved_names.truncate() # Delete all records in table\n    data = get_extracted_names()[\'resolved_names\']\n    for row in data:\n        if \'results\' in row.keys():\n            mydict = {\n                \'supplied_name_string\': row.get(\'supplied_name_string\', None),\n                \'classification_path\': row[\'results\'][0].get(\'classification_path\', None),\n                \'classification_path_ids\': row[\'results\'][0].get(\'classification_path_ids\', None),\n                \'classification_path_ranks\': row[\'results\'][0].get(\'classification_path_ranks\', None)\n            }\n            try:\n                db.resolved_names.insert(**mydict)\n                print(\'ADDED {}\'.format(row.get(\'supplied_name_string\', None)))\n                print(mydict)\n                print\n            except:\n                print(\'NOT ADDED BECAUSE OF DUP? {}\'.format(row.get(\'supplied_name_string\', None)))\n                print(mydict)\n                print\n                pass\n    return db(db.resolved_names.id>0).select()\n\n    # Now manually insert some more records\n\n    # To get data, go to http://resolver.globalnames.org/\n    # Search against the GBIF data source\n    # Copy data from JSON or XML\n    try: db.resolved_names.insert(\n            supplied_name_string = \'Musa\',\n            classification_path = \'Plantae|Tracheophyta|Liliopsida|Zingiberales|Musaceae|Musa\',\n            classification_path_ids = \'6|7707728|196|627|4686|2760990\',\n            classification_path_ranks = \'kingdom|phylum|class|order|family|genus\'\n        )\n    except: pass\n    try: db.resolved_names.insert(\n            supplied_name_string = \'Ficus\',\n            classification_path = \'Plantae|Tracheophyta|Magnoliopsida|Rosales|Moraceae|Ficus\',\n            classification_path_ids = \'6|7707728|220|691|6640|2984588\',\n            classification_path_ranks = \'kingdom|phylum|class|order|family|genus\'\n        )\n    except: pass\n    try: db.resolved_names.insert(\n        supplied_name_string = \'Artocarpus heterophyllus\',\n        classification_path = \'Plantae|Tracheophyta|Magnoliopsida|Rosales|Moraceae|Artocarpus|Artocarpus heterophyllus\',\n        classification_path_ids = \'6|7707728|220|691|6640|2984563|2984565\',\n        classification_path_ranks = \'kingdom|phylum|class|order|family|genus|species\'\n        )\n    except: pass\n    try: db.resolved_names.insert(\n        supplied_name_string = \'Rosa\',\n        classification_path = \'Plantae|Tracheophyta|Magnoliopsida|Rosales|Rosaceae|Rosa\',\n        classification_path_ids = \'6|7707728|220|691|5015|8395064\',\n        classification_path_ranks = \'kingdom|phylum|class|order|family|genus\'\n        )\n    except: pass\n    try: db.resolved_names.insert(\n        supplied_name_string = \'Colocasia esculenta\',\n        classification_path = \'Plantae|Tracheophyta|Liliopsida|Alismatales|Araceae|Colocasia|Colocasia esculenta\',\n        classification_path_ids = \'6|7707728|196|551|6979|5330758|5330776\',\n        classification_path_ranks = \'kingdom|phylum|class|order|family|genus|species\'\n        )\n    except: pass\n    # db.resolved_names.insert(\n    #     supplied_name_string = \'\',\n    #     classification_path = \'\',\n    #     classification_path_ids = \'\',\n    #     classification_path_ranks = \'\'\n    #     )\n\n    return\n\n\ndef check_name():\n    import requests\n    name = \'Nysius pulchellus\'\n    url = \'http://resolver.globalnames.org/name_resolvers.json\'\n    params = {\'names\': name, \'data_source_ids\': \'11\'}\n    r = requests.get(url, params)\n    mydict = r.json()\n    return mydict\n\n\ndef unknown_names():\n    s = \'<h1>Unknown Names</h1>\'\n    data = get_extracted_names()[\'resolved_names\']\n    for row in data:\n        if not row[\'is_known_name\']:\n            s += \'{} _{}_<br>\'.format(row[\'is_known_name\'], row[\'supplied_name_string\'])\n    return s\n\n\ndef annotate2():\n    import urllib2\n    # Download pestlist web page as a string.\n    f = urllib2.urlopen(\'https://aubreymoore.github.io/crop-pest-list/list.html\')\n    s = f.read().decode(\'utf-8\')\n    for row in db(db.resolved_names.id > 0).select():\n        supplied_name_string = row.supplied_name_string\n        taxon_id = row.classification_path_ids.split(\'|\')[-1]\n        taxon_rank = row.classification_path_ranks.split(\'|\')[-1]\n        # Is this a leaf node?\n        cp_ids = row.classification_path_ids\n        children_count = db(db.resolved_names.classification_path_ids.startswith(cp_ids)).count()\n        if children_count == 1: # This is a leaf node\n            s = s.replace(supplied_name_string,\n                    \'{} <a href="http://www.gbif.org/species/{}">{}</a>\'\n                        .format(supplied_name_string, taxon_id, taxon_id))\n    return s\n\n\ndef get_extracted_names():\n    \'\'\'\n    Returns the contents of the \'extracted_names_json\' field in the first\n    record of the \'extracted_names\' table.\n    \'\'\'\n    return db(db.extracted_names).select()[0][\'extracted_names_json\']\n\n\ndef parse_resolved_names2():\n    \'\'\'\n    Parses the JSON data stored in \'db.extracted_names.extracted_names_json\' and\n    inserts all taxa to a self-referencing table, \'db.taxon2\'. Fields in\n    this table are:\n\n        tid: taxon id; usually a GBIF taxon id\n        parent_tid: tid of the taxon\'s parent; parent of a root must be \'#\'\n        name: taxon name\n        trank: taxon rank (kingdom, phylum, class, order family, genus or species)\n        lineage: ancestors of the taxon; eg. lineage for Oryctes rhinoceros is:\n            Animalia|Arthropoda|Insecta|Coleoptera|Dynastidae|Oryctes|Oryctes rhinoceros\n\n    Dependancies:\n        get_extracted_names\n    \'\'\'\n    resolved_names_list = get_extracted_names()[\'resolved_names\']\n    for resolved_name in resolved_names_list:\n        results_list = resolved_name.get(\'results\', None)\n        if results_list:\n            result_dict = results_list[0]\n            #lineage = result_dict[\'classification_path\']\n            classification_path = result_dict[\'classification_path\'].split(\'|\')\n            classification_path_ids = result_dict[\'classification_path_ids\'].split(\'|\')\n            classification_path_ranks = result_dict[\'classification_path_ranks\'].split(\'|\')\n\n            print classification_path\n\n            assert classification_path_ranks[0] == \'kingdom\'\n            assert len(classification_path) == len(classification_path_ids)\n            assert len(classification_path_ids) == len(classification_path_ranks)\n\n            for i in range(len(classification_path)):\n                if i == 0:\n                    parent_tid = \'#\' # The hash symbol is used by jstree to signify a root node\n                else:\n                    parent_tid = classification_path_ids[i-1]\n                tid = classification_path_ids[i]\n                name = classification_path[i]\n                trank = classification_path_ranks[i]\n                lineage = \'|\'.join(classification_path[0:i+1])\n\n                try:\n                    print(\'trying to add tid={}, name={}, trank={}, lineage={}\'.format(tid, name, trank, lineage))\n                    db.taxon2.insert(tid=tid, parent_tid=parent_tid, name=name, trank=trank, lineage=lineage)\n                    print( \'{} added\'.format(name))\n                except:\n                    print(\'{} not added - already in DB?\'.format(name))\n                    pass\n    return\n\n#@auth.requires_login()\ndef show_taxon2():\n    grid = SQLFORM.grid(db.taxon2, maxtextlength=1000, paginate=1000)\n    return locals()\n\ndef find_names(doc_url):\n    \'\'\'\n    Uses the Global Names Resolver to extract scientific names from \'doc_url\'\n    which can point to an HTML or PDF document.\n    \'\'\'\n    import requests\n    import time\n\n    url = \'http://gnrd.globalnames.org/name_finder.json?\'\n    #params = {\'url\': \'https://aubreymoore.github.io/crop-pest-list/list.html\'}\n    params = {\'url\': doc_url,\n        \'data_source_ids\': \'11\',\n        \'best_match_only\': \'true\',\n        \'unique\': \'true\' }\n    r = requests.get(url, params)\n    mydict = r.json()\n    token_url = mydict[\'token_url\']\n    print(\'token_url: {}\'.format(token_url))\n\n    # Poll the token url once a second for 100 s to see if results have been returned.\n    i = 0\n    while i <= 100:\n        i += 1\n        time.sleep(1)\n        r = requests.get(token_url)\n        mydict = r.json()\n        status = mydict.get(\'status\',\'\')\n        queue_size = mydict.get(\'queue_size\',\'\')\n        print(\'{} status: {} queue_size: {}\'.format(i, status, queue_size))\n        if status != 303:\n            break\n    return(mydict)\n\n\ndef doit():\n    \'\'\'\n    Uses the find_names function to extract scientific names from\n    \'https://aubreymoore.github.io/crop-pest-list/list.html\' and stores the\n    returned JSON data in db.extracted_names.\n\n    This function runs only when the extracted_names table is empty.\n\n    Dependancies:\n        find_names\n    \'\'\'\n    if len(db(db.extracted_names).select())==0:\n        doc_url = \'https://aubreymoore.github.io/crop-pest-list/list.html\'\n        db.extracted_names.insert(extracted_names_json=find_names(doc_url))\n        return(\'Added record.\')\n    return(\'Did not add record\')\n\n\ndef index():\n    return dict(message=T(\'Welcome to pestlist!\'))\n\n\n@auth.requires_login()\ndef populate_duo():\n    db.duo.truncate() # Delete all records in table\n    data = get_extracted_names()[\'resolved_names\']\n    for row in data:\n        if \'results\' in row:\n            results_dict = row[\'results\'][0]\n            del row[\'results\']\n        else:\n            results_dict = {}\n        all_dict = row.copy()\n        all_dict.update(results_dict)\n        print row\n        print\n        print results_dict\n        print\n        print all_dict\n        print\n        db.duo.insert(**all_dict)\n    return\n\n\n@auth.requires_login()\ndef show_duo():\n    # grid = SQLFORM.grid(db.uno, maxtextlength=1000, paginate=1000)\n    rows = db(db.duo.id>0).select()\n    print(rows)\n    return dict(viewthis = rows) # or whatever instead of \'rows\'\n\n\ndef user():\n    """\n    exposes:\n    http://..../[app]/default/user/login\n    http://..../[app]/default/user/logout\n    http://..../[app]/default/user/register\n    http://..../[app]/default/user/profile\n    http://..../[app]/default/user/retrieve_password\n    http://..../[app]/default/user/change_password\n    http://..../[app]/default/user/bulk_register\n    use @auth.requires_login()\n        @auth.requires_membership(\'group name\')\n        @auth.requires_permission(\'read\',\'table name\',record_id)\n    to decorate functions that need access control\n    also notice there is http://..../[app]/appadmin/manage/auth to allow administrator to manage users\n    """\n    return dict(form=auth())\n#\n#\n# @cache.action()\n# def download():\n#     """\n#     allows downloading of uploaded files\n#     http://..../[app]/default/download/[filename]\n#     """\n#     return response.download(request, db)\n#\n#\n# def call():\n#     """\n#     exposes services. for example:\n#     http://..../[app]/default/call/jsonrpc\n#     decorate with @services.jsonrpc the functions to expose\n#     supports xml, json, xmlrpc, jsonrpc, amfrpc, rss, csv\n#     """\n#     return service()\n\nresponse._vars=response._caller(populate_duo)\n'
p7
sS'snapshot'
p8
(dp9
sS'traceback'
p10
S'Traceback (most recent call last):\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/restricted.py", line 227, in restricted\n    exec ccode in environment\n  File "/home/aubreymoore/Devel/playpen/web2py/applications/pestlist/controllers/default.py", line 341, in <module>\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/globals.py", line 417, in <lambda>\n    self._caller = lambda f: f()\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/tools.py", line 4241, in f\n    return action(*a, **b)\n  File "/home/aubreymoore/Devel/playpen/web2py/applications/pestlist/controllers/default.py", line 276, in populate_duo\n    db.duo.truncate() # Delete all records in table\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/packages/dal/pydal/objects.py", line 838, in truncate\n    return self._db._adapter.truncate(self, mode)\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/packages/dal/pydal/adapters/base.py", line 1004, in truncate\n    self.execute(query)\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/packages/dal/pydal/adapters/base.py", line 1388, in execute\n    return self.log_execute(*a, **b)\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/packages/dal/pydal/adapters/base.py", line 1382, in log_execute\n    ret = self.get_cursor().execute(command, *a[1:], **b)\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/contrib/pymysql/cursors.py", line 117, in execute\n    self.errorhandler(self, exc, value)\n  File "/home/aubreymoore/Devel/playpen/web2py/gluon/contrib/pymysql/connections.py", line 202, in defaulterrorhandler\n    raise errorclass, errorvalue\nInternalError: (1701, u\'Cannot truncate a table referenced in a foreign key constraint (`pestlist`.`duo_archive`, CONSTRAINT `duo_archive_ibfk_1` FOREIGN KEY (`current_record`) REFERENCES `pestlist`.`duo` (`id`))\')\n'
p11
s.